\documentclass[11pt]{article}
\usepackage{acl2012}
\usepackage{times}
\usepackage{latexsym}
\usepackage{amsmath}
\usepackage{multirow}
\usepackage{url}
\DeclareMathOperator*{\argmax}{arg\,max}
\setlength\titlebox{6.5cm}    % Expanding the titlebox


\title{Geolocating Wikipedia Articles Using Label Propagation}

\author{
  Aidan Coyne \\
    Department of Computer Science\\
    The University of Texas at Austin\\
  {\tt coynea90@gmail.com} \\ 
  \And
  Prateek Maheshwari\\
    Department of Computer Science\\
    The University of Texas at Austin\\
  {\tt prateekm@utexas.edu}
}

\date{}

\begin{document}
\maketitle

\section{Introduction}
% Add a brief introduction to geolocation and why it is useful.
% Why choose wikipedia?
Other work (cite kumar, bald ridge, lease) has shown that language models learnt from wikipedia can be used for prediction tasks in other domains.

Prior work on geolocating Wikipedia articles has focused on (used for training) a subset of the english language Wikipedia; 
% \cite{wing and baldridge} \cite{rolleretal:12} \cite {efran et al} 
specifically, those articles that already have geotags associated with them. % is this true? or do they only use this for training?
These articles constitute a relatively small fraction of the english language wikipedia. %find actual figure
On the other hand, the fraction of articles that link to geolocated articles is %find figure
of the wikipedia corpus. This isn't surprising, since most articles on wikipedia are not about specific locations, or objects at specific locations.
However, there are many other articles that may be associated with one or more places; 
for example, biographical articles may refer to the various locations the subject has lived or worked at.

Even within the geotagged articles, earlier approaches only use the geo-information present in the article metadata, and the article text is used only on a coarse level %rephrase
by building language models out of it.

Our hypothesis is that we can infer the location for non-geotagged articles 
by using the location information present in other geotagged articles that they link to. 
Unlike prior work, this approach makes use of the link structure of the articles in addition to the metadata and text based language models. 
We propose to infer the location using label propagation.

We also propose that these additional geo-located articles can help improve the language models used for geo-locating other articles by appropriately smoothing them.

\section{Related Work}
%Geolocation
Geolocation can be implemented as an IR task, as explained in \cite{skiles:12};
IR-based implementations divide the world up into cells, each
of which are considered to be a pseudo-document consisting of text from every
document appearing in that cell.
The simple approach, used by \cite{wing-baldridge:11}, is to divide the world
into cells of uniform size (or rather, equal degrees);
\cite{rolleretal:12} develop an adaptive grid based on kd-trees that splits cells in order to
allocate uniform amounts of text to each cell; 
they also determine that using the centroid of document geolocations as the
cell center tends to perform better than using the cell midpoint (as in
\cite{wing-baldridge:11}), even in the uniform-grid case.
A different model for geolocation is presented by \cite{eisensteinetal:11}; it
is a general generative model presented as an alternative to LDA.

%something on label propogation
\cite{talukdar:09} \cite{talukdar:10}

\section{Plan of Work}
We will use the Junto toolkit \cite{junto} for label propagation using the Modified Adsorption algorithm.
We will also use the tesxtgrounder toolkit for evaluating our results and obtaining a grid structure.

In the first stage of the project, we will examine the accuracy of label propagation alone in
geolocating wikipedia documents. For this, we will divide geotagged wikipedia documents
into training and testing sets and measure the prediction accuracy over the testing set.


%Various options will have to be examined in setting up the label propagation system.
To use label propagation, we need to divide regions of the world based on a grid; 
the world can be divided into smaller grid cells using a number of schemes. 
While several such schemes are conceivable, we will use uniform grid cells or the KD-trees based adaptive grid of \cite{rolleretal:12}, for ease of use and comparable evaluation. 
The nodes in the graph are wikipedia documents, and the labels are the "bins" or 
grid cells that they fall in. The edge weights are a measure of similarity between the nodes, 
and the notion of similarity between documents needs to be decided upon. 
Some of the options are %options to explore

Other issues to explore involve determining the structure of the graph 
(directed or undirected, dense or sparse, edge weights), the algorithm to use 
(three possible algorithms) and optimum parameters for the selected algorithm. 

Based on the work in \cite{rolleretal:12}, the predicted location of a document will be chosen as the 
centroid of the label (grid cell) with the highest weight. Alternatively, we can explore the possibility of
using the top $k$ labels for predicting the location.
%not sure if this is a good idea, top k cells don't have to be adjacent.

Once we predict the location of the unlabeled documents, 
we can include the text from those documents
while constructing the language models for the cells they belong to 
to provide additional information or smoothing.
While outside the scope of this project, an important problem is to determine this set of documents 
that can benefit from label propagation and should be included in the final language model.

\section{Evaluation}
We test the performance of label propagation against the geolocation results from textgrounder. 
It should be noted that the aim of the project is not to beat the results obtained using textgrounder,
but instead to get a reasonable geolocation accuracy on non-geotagged articles 
so that they can be included in the language model for textgrounder cells. 
If we can obtain an accuracy close to that of textgrounder on the geotagged corpus, 
we can be sure that the results for non-geotagged documents will be useful.

%Applying a label-propagation model to geolocation should be fairly straightforward; 
%provide known correct labeling for the nodes in the training set, run the label
%propagation system, and examine the labeling of the nodes in the test set.
% - this goes in the plan of work section

To evaluate the performance of the models, we will use measures based on error distances, 
e.g, mean and median error between predicted and actual distance,  
instead of IR based methods like precision or recall.

\par
The motivation for all of this is to extend geolocation to the vast unlabeled
section of wikipedia; with two different models, each with a variety of
parameters, there are multiple ways to go about this.
One scheme would be to use the geolocated portion to train Textgrounder and
compare its predictions for the unlabeled set to the predictions yielded by
running label propagation over the combined sets.

\bibliographystyle{acl2012}
\bibliography{refs}
\end{document}
