\documentclass[11pt]{article}
\usepackage{acl2012}
\usepackage{times}
\usepackage{latexsym}
\usepackage{amsmath}
\usepackage{multirow}
\usepackage{url}
\DeclareMathOperator*{\argmax}{arg\,max}
\setlength\titlebox{6.5cm}    % Expanding the titlebox
\newcommand{\comment}[1]{}


\title{Geolocating Wikipedia Articles Using Label Propagation}

\author{
  Aidan Coyne \\
    Department of Computer Science\\
    The University of Texas at Austin\\
  {\tt coynea90@gmail.com} \\ 
  \And
  Prateek Maheshwari\\
    Department of Computer Science\\
    The University of Texas at Austin\\
  {\tt prateekm@utexas.edu}
}

\date{}

\begin{document}
\maketitle

\section{Introduction}
\comment{You can now enclose text in a comment block to comment it out inline}
% Add a brief introduction to geolocation and why it is useful.
With the widespread use of mobile devices, geographic information is becoming ubiquitous. Geographic information is relevant in many contexts, for example, 
geographic information retrieval for exploring document collections \cite{}, toponym resolution in historical texts \cite{perseus project},  summarizing travelogues and travel recommendation \cite{hao},
socio-linguistic studies \cite{eisenstien}, targeted advertising etc.

% Why choose wikipedia?
Wikipedia is a good source of semi-structured data and world knowledge. The use of wikipedia for article geolocation, classification and toponym resolution
 was suggested in \cite{Overall09}. While he only used the metadata associated with the articles, 
others have extended his approach by adopting a language modeling approach and using article text to predict article location \cite{wing-baldridge:11}. Furthermore,
(kumar2011supervised) have shown that language models learnt from wikipedia can be used for prediction tasks in other domains.

Prior work on geolocating Wikipedia articles (\cite{wing-baldridge:11} \cite{rolleretal:12}) has so far only used 
a subset of the english language Wikipedia for training prediction models;  specifically, those articles that already have location tags associated with them.  
These articles constitute a relatively small fraction of the english language wikipedia. \comment{find actual figure}
This isn't surprising, since most articles on wikipedia are not about specific locations, or objects at specific locations.

Even within the geotagged articles, earlier approaches only use the geo-information present in the article metadata, 
and the article text is used only on a coarse level by building language models out of it.

However, there are many other articles that may be associated with one or more places;  for example, biographical articles may refer to the various locations the subject has lived or worked at.
On the other hand, the fraction of articles that link to geolocated articles is much larger, and provides an extra resource that can be used. \comment{ find figure  of the wikipedia corpus}

Our hypothesis is that we can infer the location for non-geotagged articles by using the location information present in other geotagged articles that they link to. 
Unlike prior work, this approach makes use of the link structure of the articles in addition to the location metadata and text based language models. 
We propose to infer the location using label propagation.

We also propose that these additional geo-located articles can help improve the language models used for geo-locating other articles by appropriately smoothing them.

\section{Related Work}
%Geolocation
Geolocation can be implemented as an IR task, as explained in \cite{skiles:12}; 
IR-based implementations divide the world up into cells, each of which are considered to be a pseudo-document consisting of text from every document appearing in that cell.
Documents can then be geolocated by comparing their language model with the language models from each of the grid cells and assigning the document to the cell with which
it has the highest similarity scores.
The simple approach, used by \cite{wing-baldridge:11}, is to divide the world into cells of uniform size (or rather, equal degrees).
\cite{rolleretal:12} develop an adaptive grid based on kd-trees that splits cells such that they contain roughly equal number of documents.
They also show that centroid of locations of document in the grid cell as the cell's location results in more accurate predictions than using the mean of document locations (as in
\cite{wing-baldridge:11}), even in the uniform-grid case. A different model for geolocation is presented by \cite{eisensteinetal:11}; it
is a general generative model presented as an alternative to LDA \comment{who uses LDA?}. There are other works on geolocation that focus
explicitly on the linguistics features of the documents by removing any references to locations present in the text \cite{paper}

%something on label propogation
Label propagation is a general purpose graph-based semi-supervised learning algorithm \cite{talukdar:09} \cite{talukdar:10} with many uses. 
Given a graph G = {V, E, W}, where V are the graph vertices, E are the edges and W is a matrix representing the edge weights, 
label propagation algorithms produce a set of class labels for each node in the graph starting from a small seed set of labeled nodes. 
The algorithm iteratively propagates the labels on the seed nodes to their neighbors in proportion to the weight of the edge between them 
while keeping the labels on the seed nodes fixed. The edge weights are chosen to be proportional to the similarity between the nodes. 
Label propagation has been used for sentiment analysis \cite{sperisou}, community detection \cite{talukdar}, 
classification and ranking \cite{something} \comment{and recommendation, youtube}. 

%something on using gazetteers for toponym resolution


\section{Plan of Work}
Following the methodology in \cite{wing-baldridge:11}, we will use the 2010 wikipedia dump for evaluation. 
After cleanup and processing, the dump contains 3,431,722  articles, of which 488,269 are geotagged. 
The number of articles that link directly to geotagged articles is to be determined.

We will use the textgrounder \cite{textgrounder} toolkit for creating the grids to be used for document geolocation and for evaluating our results. 
We will use the Junto toolkit \cite{junto} for label propagation using the Modified Adsorption algorithm.

In the first stage of the project, we will determine the accuracy of label propagation for
geolocating wikipedia documents. For this, we will train and test on pre-geotagged wikipedia documents
into training and testing sets and measure the prediction accuracy over the testing set.
If time permits, we will examine the accuracy of geolocation on augmenting the pseudo-documents
in textgrounder with additional info from non-geotagged documents.


For geolocation, the world can be divided into smaller grid cells using a number of ways. We will initially evaluate and tune the performance of label propagation
using a uniform grid for ease of use and so that we can compare our model to that of \cite{wing-baldridge:11}. Later, we can easily substitute it with 
the more accurate KD-trees based adaptive grid of \cite{rolleretal:12}.

Based on the work in \cite{rolleretal:12}, the predicted location of a document will be chosen as the 
centroid of the label (grid cell) with the highest weight. Alternatively, we can explore the possibility of
using the top $k$ labels for predicting the location.
%not sure if this is a good idea, top k cells don't have to be adjacent.

The nodes in the graph to be used for propagating labels will be wikipedia documents, and the labels will be the grid cells that the documents fall in.
We will use a fixed subset of the geotagged portion of wikipedia as the seed nodes. It would be informative to examine the accuracy of label propagation
as a function of the number of seed documents. 

Since each document can potentially be related to more than one location, one question to examine is whether 
it is better to clamp the label distribution on the seed documents to the unique, original label, or to allow it to evolve and acquire nonzero weights for other locations.
One reason to do that would be to allow a document label to be influenced by closely tied geographic locations. For example, the distribution for the document for 
Lake Austin would have nonzero weight for the location for Travis County, from their mutual references to the document for Austin.


Other issues to explore involve determining the structure of the graph to be used for label propagation. One aspect to examine is whether the graph 
should be directed, with edges pointing from referring document to the referred document, or undirected. Another important consideration is the method to be used
for inducing the edges between documents; for example, whether the edges are based solely on hyperlinks between nodes (i.e., present only when one document
refers another), whether the edges are transitive (i.e, if the document for Austin links to the document for Houston, and the document for Houston links to the document for Dallas, 
should the document for Austin have a link to the document for Dallas. A related issue is to determine whether the label propogation algorithm works better with a dense graph 
with many edges between nodes, or with a sparse graph with a few strong connections.
  
A third issue is to determine the weights of edges. Intuitively, the weight of an edge is proportional to the similarity of the two nodes (documents) it is connecting. 
Formalizing this notion of similarity is important, and can be done in a number of ways. One way to do that would be to take the 
similarity between the language models for the two documents as the edge weights. This could be the cosine similarity, tf-idf weighted cosine similarity, the KL divergence, etc.
Another option is to use a fixed and constant edge weight for each pair of documents that refer to one another. Additionally, we could induce an edge between all documents 
that fall in a particular grid cell to increase locality, or between documents in adjacent cells, to introduce smoothing.
 
We will also explore the optimum parameters for the label propagation algorithm (initial seed weights, etc).

\section{Evaluation}
We will test the performance of label propagation against the geolocation results from textgrounder. 
It should be noted that the aim of the project is not to beat the results obtained using textgrounder,
but instead to get a reasonable geolocation accuracy on non-geotagged articles 
so that they can be included in the language model for textgrounder cells. 
If we can obtain an accuracy close to that of textgrounder on the geotagged corpus, 
we can be sure that the results for non-geotagged documents will be useful.

%Applying a label-propagation model to geolocation should be fairly straightforward; 
%provide known correct labeling for the nodes in the training set, run the label
%propagation system, and examine the labeling of the nodes in the test set.
% - this goes in the plan of work section

To evaluate the performance of the models, we will use measures based on error distances, 
e.g, mean and median error between predicted and actual distance,  
instead of IR based methods like precision or recall.

\section{Timeline}
1. dataset preparation
2. tools exploration
3. measuring efficiency of label propagation on geotagged documents

\section{Future Work}
Although beyond the scope of this project, there are other ideas that could be tried in conjugation with our work.

Once we predict the location of the unlabeled documents, we can include the text from those documents
while constructing the language models for the cells they belong to provide additional information or smoothing.
While outside the scope of this project, an important problem is to determine this set of documents 
that can benefit from label propagation and should be included in the final language model.

Using mean-shift clustering as in \cite{Grauman} for detecting locations instead of a discrete grid.
Using NER to detect location references in addition to explicit links.
Using label propagation for geolocating twitter users from their connection graph.

%\par
%The motivation for all of this is to extend geolocation to the vast unlabeled
%section of wikipedia; with two different models, each with a variety of
%parameters, there are multiple ways to go about this.
%One scheme would be to use the geolocated portion to train Textgrounder and
%compare its predictions for the unlabeled set to the predictions yielded by
%running label propagation over the combined sets.

\bibliographystyle{acl2012}
\bibliography{refs}
\end{document}
